
\section{Hadron collisions at high energies}
In hadron collisions at as sufficiently high momentum transfer, all partons can be approximated as free  making it possible to treat hadron-hadron scattering as a single parton-parton interaction. The momentum of the parton can then be expresses as a fraction of the hadron momentum 
\begin{equation}
 \vec{p}_{\mathrm{parton}} = x \vec{p}_{\mathrm{hadron}}, 
\end{equation}
where $x$ is referred to as the Bj\"orken scaling variable. The interaction $\Pproton_{\mathrm{A}} \Pproton_{\mathrm{B}} \rightarrow \mathrm{X}$ can then be factorised in terms of partonic cross sections $\hat{\sigma}_{\mathrm{ij}\rightarrow\mathrm{X}}$~\cite{Collins:1989gx}
\begin{equation}
 \sigma_{\mathrm{p}_{\mathrm{A}}\mathrm{p}_{\mathrm{B}}\rightarrow\mathrm{X}} = \sum \limits_{\mathrm{ij}} \iint dx_1 dx_2  \: f_{\mathrm{i}}^{\mathrm{A}}(x_{\mathrm{1}},Q^2)f_{\mathrm{j}}^{\mathrm{B}}(x_{\mathrm{2}},Q^2) {d\hat{\sigma}_{\mathrm{ij}\rightarrow\mathrm{X}}}, 
 \label{eq:cross}
 \end{equation}
where i and j are the partons resolved from protons A and B,  $f_{\mathrm{i}}(x_{\mathrm{i}},Q^2)$ the parton density functions (PDF), and $Q^2$ the factorisation scale more commonly denoted as \muF. The factorisation scale is the scale at which the hadronic interaction can be expressed as a product of the partonic cross section and the process independent PDF. In \fig{fig:factoscale}, the kinematic regions in $x$ and \muF\ are shown for fixed target and collider experiments.
\begin{figure}
	\centering
	\includegraphics[width=0.5\linewidth]{3_Analysis_techniques/Figures/factoscale}
	\caption{Kinematic regions in momentum fraction $x$ and factorisation scale $Q^2$ probed by fixed-target and collider experiments. Some of the final states accessible at the LHC are indicated in the appropriate regions, where $y$ is the rapidity. In this figure, the incoming partons have $x_{1,2} = (M/14 \TeV)e^{\pm y}$ with $Q = M$ where $M$ is the mass of the state shown in blue in the figure. For example, exclusive J$/\psi$ and $\Upsilon$ production at high $|y|$ at the LHC may probe the gluon PDF down to $x \sim  10^{-5}$. Figure taken from \cite{PDG}.}
	\label{fig:factoscale}
\end{figure}




 The parton density functions (PDF)~\cite{Placakyte:2011az,Ball2015,Butterworth:2015oua} give the momentum distribution of the proton amongst its partons at an energy scale \muF.  
  These function can not be determined from first principles and have to obtained from global fits to data. The PDFs are obtained from measurements on deep inelastic scattering using lepton-proton collision by the HERA collider~\cite{Abramowicz:1998ii}, supplemented with proton-antiproton collisions from Tevatron at Fermi lab~\cite{Holmes:2011ey}, and proton collision data from the ATLAS, CMS and LHCb collaborations at the LHC (Run 1)~\cite{Rojo:2015acz}. These measurements are included in global PDF sets known as the \texttt{PDF4LHC} recommendation~\cite{Butterworth:2015oua}. From their measurement at scale \muF\ these PDFs can be extrapolated using the DGLAP equations \todocite. The PDFs are used to calculate the cross section of a certain process and are therefore used as input for the Monte Carlo generators used to make the simulated data samples at the LHC. 
%https://amva4newphysics.wordpress.com/2016/03/10/the-inner-life-of-protons-and-artificial-neural-networks/
In the framework of this thesis, the NLO \texttt{PDF4LHC}15\_100 set is used. This set is an envelope of three sets, \texttt{CT14}, \texttt{MMHT2014} and \texttt{NNPDF3.0}~\cite{Butterworth:2015oua}. In \fig{fig:nnpdf30} the dependency of the PDFs on the momentum fraction $x$ is shown for the \texttt{NNPDF3.0} set on hadronic scale ($\muF^2 = (10\GeV)^2$ and LHC scale ($\muF^2 = (10^4\GeV)^2$. For most values of the momentum fraction, the gluon density dominates, meaning that it is easier to probe muons than the quarks. For $x$ close to one, the parton densities of the up and down quarks (the valence quarks of the proton) dominate over the gluon density. The charm, anti-up, and anti-down quarks have lower densities in general since those are sea quarks which originate in the proton only through gluon splitting. 
The resolution scale $Q^2$ is typically taken to be the energy scale of the collision. For the top quark pair production a scale of $Q^2=(350\: \GeV)^2$ is chosen, meaning that the centre-of-mass energy of the hard interaction is about twice the top quark mass.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.7\linewidth]{3_Analysis_techniques/Figures/NNPDF30}
	\caption{The momentum fraction $x$ times the parton distribution functions $f(x)$, where $f=\Pup_{\mathrm{v}}, \Pdown_{\mathrm{v}} ,\APup,\APdown,\Pstrange,\Pcharm,$ or \Pgluon\ as function of the momentum fraction obtained in the NNLO \texttt{NNPDF3.0} global analysis at factorisation scales $\mu^2 = 10 \: \GeV^2$ (left) and $\mu^2=10^4 \: \GeV^2$ (right), with $\alpha_{\mathrm{S}}(M^2_{\PZ}) = 0.118$. The gluon PDF has been scaled down by a factor of 0.1. Figure taken from \cite{PDG}.}
	%http://pdg.lbl.gov/2017/reviews/rpp2016-rev-structure-functions.pdf
	% The higher value of the resolution scale $Q^2$, the smaller distances that are probed in the proton.
	\label{fig:nnpdf30}
\end{figure}
The uncertainty on the parton distributions is evaluated using the Hessian technique~\cite{Pumplin:2001ct}, where a matrix with a dimension identical to the number of free parameters needs to be diagonalised. In the case of \texttt{PDF4LHC}15\_100 set, this translates into 100 orthonormal eigenvectors and 200 variations of the PDF parameters in the plus and minus direction. 
%https://www.hep.ucl.ac.uk/pdf4lhc/LesHouches2016-PDF4LHC.pdf
%https://indico.cern.ch/event/525605/contributions/2152733/attachments/1267702/1877336/TOP_PAG_3_05_16_PDFs.pdf

At high energies divergences can appear from quantum fluctuations. For the theory still to be able to describe the experimental regime, a renormalization scale \muR\ is used to redefine physical quantities A consequence of this method is that the coupling constants will run as function of \muR. Beyond this scale, the high energy effects such as the loop corrections to propagators (self energy) are absorbed in the physical quantities through a renormalization of the fields. In particular the running behaviour of the strong coupling constant\footnote{The strong coupling constant is defined as $\alpha_{\mathrm{S}} = \frac{g_\mathrm{S}^2}{4\pi}$. } $\alpha_{\mathrm{S}}$ is found to be 
\begin{equation}
	\alpha_{\mathrm{S}} = \frac{\alpha_{\mathrm{S}}(\mu_0^2)}{1 + \alpha_{\mathrm{S}}(\mu_0^2) \frac{33 - 2 n_{\mathrm{f}}}{12 \pi}\mathrm{ln}\left(\frac{|\muR^2|}{\mu_0^2}\right)}, 
	\label{eq:couplingstrength}
\end{equation}
with $n_{\mathrm{f}}$ the number of quarks and $\mu_0$ the reference scale on which the coupling is known. The current world average of the strong coupling constant at the \PZ boson mass is $\alpha_{\mathrm{S}}(\muF = \mZ) = 0.1181 \pm 0.0011$~\cite{PDG}. From  \eq{eq:couplingstrength} one can see easily that the coupling strength decreases with increasing renormalization scale, this known as asymptotic freedom. Additionally, following the behaviour of $\alpha_{\mathrm{S}}(\muR^2)$, a limit $\Lambda_{\mathrm{QCD}} \approx 200 \: \MeV$ is found for which $\alpha_{\mathrm{S}}$ becomes larger than one. Under this limit, the perturbative calculations of observables can no longer be done.
% Mandl and shaw pagina 352!



%The cross section $\sigma$ of scattering process with a flux\footnote{This entity is more commonly referred to as Luminosity.} $\lumi= \rho v$ of incoming particles with particle density $\rho$ and velocity $v$ is defined as the number of interactions per unit density ($\rho=1$)\footnote{The cross section is usual expressed in barn, $1b = 10^{-28}\m^2$. The number of interactions per time is given by $\frac{dN}{dt} = \lumi \sigma$}. 
Cross sections be written in terms of interacting vertices contributing to the matrix element (ME) originating from elements of a perturbative series~\cite{Mandl:1236742}, allowing them to be expanded as a power series of the coupling constant $\alpha$ 
\begin{equation}
 \sigma  = \sigma_{\mathrm{LO}} \left(1 + \left(\frac{\alpha}{2\pi}\right)\sigma_1  + \left(\frac{\alpha}{2\pi}\right)^2\sigma_2 + ...\right).
\end{equation}
Leading order (LO) accuracy contains the minimal amount of vertices in the process, then depending on where the series is cut off one speaks of next-to-leading order (NLO), or next-to-next-to-leading order (NNLO) accuracy in $\alpha$. Predictions including higher order correction tend to be less affected by theoretical uncertainties originating from a variation of the chosen renormalization and factorisation scales. 
% zie thesis matthias p 21 bovenaan

\section{Event generation}
In order to compare reconstructed data with theoretical predictions, collision events are generated and passed through a simulation of the CMS detector and an emulation of its readout. For the detector simulation, a so-called Full Simulation package~\cite{1742-6596-396-2-022003,1742-6596-664-7-072022}  based on the \Geant4 toolkit~\cite{AGOSTINELLI2003250} is employed. It allows a detailed simulation of the interactions of the particles with the detector material. 
\subsection{Fundamentals of simulating a proton collision}
The procedure of to generate $\Pproton\Pproton \rightarrow \mathrm{X}$ events can be subdivided into sequential steps~\cite{Seymour:2013ega,Sjostrand:2009ad,Hoche:2014rga}, as shown in \fig{fig:ppcollision}.
\begin{figure}[htbp]
	\centering
	\includegraphics[width=1.\linewidth]{3_Analysis_techniques/Figures/MCeventwithlegend}
	\caption{Sketch of a hadron collision as simulated by a Monte-Carlo event generator. The red blob in the centre represents the hard collision, surrounded by a tree-like structure representing Bremsstrahlung as simulated by parton showers. The purple blob indicates a secondary hard scattering event. Parton-to-hadron transitions are represented by light green blobs, dark green blobs indicate hadron decays, while yellow lines signal soft photon radiation. Figure taken from~\cite{Hoche:2014rga}.}
	\label{fig:ppcollision}
\end{figure}

The interaction of two incoming protons is often soft and elastic leading to events that are not interesting in the framework of this thesis. More intriguing are the hard interaction between two partons from the incoming protons. The matrix elements   of a hard scattering process of interest is the starting point of the generation of events. Monte Carlo techniques are used to sample the corresponding cross section integral and the resulting sample of events reflect the probability distribution of a process over its final state phase space. After obtaining the sample of events of the hard interaction, a parton shower (PS) program is used to simulate the hadronisation of final state partons into hadrons which then  decay further. Additionally, radiation of soft gluons or quarks from initial or final state partons is simulated. These are respectively referred to as initial state radiation (ISR) or final state radiation (FSR). Contributions from soft secondary interactions, the so-called underlying event (UE), and colour reconnection effects are also taken into account. \todo{Should I add more details?}
A brief overview of the employed programs used for the event generation of the signal and main background processes used in the search presented in the thesis are given in \Sec{sec:programs}.

\subsection{Programs for event generation}
\label{sec:programs}
The \texttt{FEYNRULES} package~\cite{Alloul:2013bka} allows the calculation of  the Feynman rules in momentum space for any quantum field theory model. By use of a Lagrangian, the set of Feynman rules associated with this Lagrangian are calculated. Via the \UFO\ (UFO)~\cite{Degrande:2011ua} the results are then passed to matrix element generators. 


The \MG\  program~\cite{Alwall:2011uj} is used to interpret the physics model and calculate the corresponding Feynman diagrams and matrix elements. After this, \ME~\cite{Mangano:2006rw} is used to calculate the corresponding partons. These generated parton configurations are then merged with \Pythia~\cite{Sjostrand2015159,Sjostrand:2006za,Sjostrand:2014zea} parton showers using the MLM merging scheme~\cite{Alwall:2007fs}. 

The \aMCMG\ program~\cite{Alwall:2014hca} combines the LO \MG~\cite{Alwall:2011uj} and the \aMC\ program into a common framework. This combination supports the generation of samples at LO or next to NLO together with a dedicated matching to parton showers  using the MLM~\cite{Alwall:2007fs} or FXFX~\cite{Frederix:2012ps} schemes respectively. The FXFX scheme produces a certain fraction of events with negative weights originating from the subtraction of amplitudes that contain additional emissions from the NLO matrix element to prevent double-counting.
%or MC$@$NLO~\cite{Frederix:2012ps}  \todo{MC$@$NLO voor ME generator }



The \Powheg\ box (versions 1,2)~\cite{Alioli2010,1126-6708-2009-09-111,1126-6708-2007-11-070,Alioli:2010xd,Frixione:2007vw,Nason:2004rx} contains predefined implementations of various processes at NLO. It applies the \Powheg\ method for ME- to PS- matching, where the hardest radiation generated from the ME has priority over subsequent PS emission to remove the overlap with the PS simulation.

The \JHU\ generator (version 7.02)~\cite{Gritsan:2016hjl,Anderson:2013afp,Bolognesi:2012mm,Gao:2010qx} is used to generate the parton level information including full spin and polarization correlations. It is commonly used for studying the spin an parity properties of new resonances such as $\mathrm{ab}\rightarrow\mathrm{X}\rightarrow \mathrm{VV}$, where $\mathrm{V} = \PZ, \PW, \Pphoton)$. 

The generation of events from processes involving the production and decay of resonances creates a computational heavy load, especially at NLO. The narrow width approximation the resonant particle is assumed to be on-shell. This makes the production and decay amplitude factorize, allowing to perform the simulation of the production and decay of heavy resonances like top quarks or Higgs bosons to be performed in separate steps. The \MS\ program~\cite{Artoisenet:2012st} extends this approach and accounts for off-shell effects through a partial reweighting of the events. Additionally, spin correlation effects between production and decay products are taken into account. 

The \Pythia\ program (versions 6,8)~\cite{Sjostrand2015159,Sjostrand:2006za,Sjostrand:2014zea} generates events of various processes at LO. Usually in the analysis, it is however only used for its PS simulation and it is interfaced with other LO and NLO event generators to perform subsequent parton showering, hadronisation, and simulation of the underlying event.  In this thesis the underlying event tunes~\cite{Khachatryan2016}  are the CUETP8M2T4, CUETP8M1 and CUETP8M2. 





The detector response is simulated via the \Geant 4~\cite{AGOSTINELLI2003250} program. This program tracks the particles through the detector material via a detailed description of the detector and generates several hits throughout several sensitive layers. 
In addition, the response of the detector electronics to these hits are simulated. 


\subsection{Generating FCNC top-Z interactions}
The FCNC processes are generated by interfacing the Lagrangian in \eq{eq:EFTlag} with \aMCMG\ by means of the \FR\ package and its  \UFO\ format.  The complex chiral parameters are arbitrary chosen to be $f^{\mathrm{L}}_{\mathrm{X}\Pquark} = 0$ \todo{Why LH and not RH?} and  $f^{\mathrm{R}}_{\mathrm{X}\Pquark} = 1$. The signal rates are estimated by use of the \aMCMG\ program for estimating the partial widths. The anomalous couplings are left free to float for this estimation, and only one coupling allowed to be non-vanishing at a time. The results are presented in \tab{tab:partialwidths}.
\begin{table}[htbp]
	\centering
	\caption{Leading order partial widths related to the anomalous decay modes of the top quark, where the new physics scale $\Lambda$ is given in \GeV.}
	\begin{tabular}{ccll}
		\toprule
		Anomalous coupling & vertex & \multicolumn{2}{c}{Partial decay width  (\GeV) }\\ 
		\midrule
		\multirow{2}{*}{\kgqtl} & \Ptop\Pgluon\Pup      &  3.665220 $10^{5}$   & $\left( \kappa_{\Ptop\Pgluon\Pup} / \Lambda \right)^2$ \\
		                    & \Ptop\Pgluon\Pcharm       &  3.664620 $10^{5}$   & $\left( \kappa_{\Ptop\Pgluon\Pcharm} / \Lambda \right)^2$ \\
	    \multirow{2}{*}{\kfqtl} & \Ptop\Pphoton\Pup     &  1.989066 $10^{4}$   & $\left( \kappa_{\Ptop\Pphoton\Pup} / \Lambda \right)^2$ \\
		                    & \Ptop\Pphoton\Pcharm      &  1.988904 $10^{4}$   & $\left( \kappa_{\Ptop\Pphoton\Pcharm} / \Lambda \right)^2$    \\
		\multirow{2}{*}{\kZqtl} & \Ptop\PZ\Pup          &  1.637005 $10^4$     & $\left( \kappa_{\Ptop\PZ\Pup} / \Lambda \right)^2$     \\
		                    & \Ptop\PZ\Pcharm           &   1.636554 $10^4$    & $\left( \kappa_{\Ptop\PZ\Pcharm} / \Lambda \right)^2$  \\
		\multirow{2}{*}{\zZqt} & \Ptop\PZ\Pup           &   1.685134 $10^{-1}$ & $\left( \zeta_{\Ptop\PZ\Pup}  \right)^2$ \\
		                    & \Ptop\PZ\Pcharm           &   1.684904 $10^{-1}$ & $\left( \zeta_{\Ptop\PZ\Pcharm} \right)^2$ \\
	    \multirow{2}{*}{\eHqt} & \Ptop\PHiggs\Pup       &   1.904399 $10^{-1}$ & $\left( \eta_{\Ptop\PHiggs\Pup}  \right)^2$  \\
		                    & \Ptop\PHiggs\Pcharm       &   1.904065 $10^{-1}$ & $\left( \eta_{\Ptop\PHiggs\Pcharm}  \right)^2$ \\
			\bottomrule
	\end{tabular} 
	\label{tab:partialwidths}
\end{table}
The anomalous single top cross sections are calculated by convolution of the hard scattering matrix elements with the LO order set of \CTEQ 6 partons densities~\cite{Pumplin:2002vw}. The NLO effects are modelled by multiplying each LO cross section by a global $k$-factor. The LO single top production cross section and the global $k$-factors for the top-\PZ production are shown in \tab{tab:STx}. The hard scattering events are then matched to parton showers to \Pythia\ to account for the simulation of the QCD environment relevant for hadronic collisions. 
\begin{table}[htbp]
	\centering
	\caption{Leading order single top production cross section for $\Pproton\Pproton \rightarrow \tZ$ or \tbarZ, where the new physics scale is given in \GeV. The NLO $k-$factors~\cite{Zhang:2011gh} are given in the last column.}
	\begin{tabular}{cllc}
		\toprule
	   Anomalous coupling & \multicolumn{2}{c}{Cross section (\pb)} &  NLO $k-$factor \\ 
		\midrule
	    $\kappa_{\Ptop\Pgluon\Pup} / \Lambda $     &  3.272 $10^7$  & $\left( \kappa_{\Ptop\Pgluon\Pup} / \Lambda \right)^2$ & 1.00 \\
	    $\kappa_{\Ptop\Pgluon\Pcharm} / \Lambda $  &  3.021 $10^6$  & $\left( \kappa_{\Ptop\Pgluon\Pcharm} / \Lambda \right)^2$ & 1.00 \\
	    $\kappa_{\Ptop\Pphoton\Pup} / \Lambda $    &  2.260 $10^5$  & $\left( \kappa_{\Ptop\Pphoton\Pup} / \Lambda \right)^2$ & 1.00 \\
	    $\kappa_{\Ptop\Pphoton\Pcharm} / \Lambda $ &  2.654 $10^4$  & $\left( \kappa_{\Ptop\Pphoton\Pcharm} / \Lambda \right)^2$ & 1.00 \\
	    $\kappa_{\Ptop\PZ\Pup} / \Lambda $         &  1.728 $10^6$  & $\left( \kappa_{\Ptop\PZ\Pup} / \Lambda \right)^2$ & 1.40 \\
	    $\kappa_{\Ptop\PZ\Pcharm} / \Lambda $      &  2.040 $10^5$  & $\left( \kappa_{\Ptop\PZ\Pcharm} / \Lambda \right)^2$ & 1.40 \\
	    $\zeta_{\Ptop\PZ\Pup} $                    &  7.484         & $\left( \zeta_{\Ptop\PZ\Pup} \right)^2$ & 1.40 \\
	    $\zeta_{\Ptop\PZ\Pcharm} $                 &  1.038         & $\left( \zeta_{\Ptop\PZ\Pcharm}  \right)^2$ & 1.40 \\
       \bottomrule
	\end{tabular} 
	\label{tab:STx}
\end{table}

The top pair cross sections are derived from the \SM\ \ttbar\ cross section, calculated with \aMCMG\ at NLO ($\sigma_{\ttbar} = 6.741 \; 10^{2} \pb$), and considering the decay $\ttbar \rightarrow (\Pbottom \PWpm)(\mathrm{X}\Pquark\Ptop)$. The branching ratio $\BR(\Ptop \rightarrow \Pbottom\PWpm)$ is assumed to be equal to one and the FCNC branching ratio is calculated as 
\begin{equation}
 \BR(\Ptop \rightarrow \Pquark\mathrm{X}) = \frac{ \Gamma_{\Ptop \rightarrow \Pquark\mathrm{X}} }{\Gamma_{\Ptop}^{\mathrm{SM}} + \Gamma_{\Ptop}^{\mathrm{FCNC}} }
 		\approx  \frac{ \Gamma_{\Ptop \rightarrow \Pquark\mathrm{X}} }{\Gamma_{\Ptop}^{\mathrm{SM}}} , 
\end{equation}
where $\Gamma_{\Ptop \rightarrow \Pquark\mathrm{X}}$ is given in \tab{tab:partialwidths}, and the assumption $ \Gamma_{\Ptop}^{\mathrm{FCNC}} \ll \Gamma_{\Ptop}^{\mathrm{SM}}$ is made \todo{these partial widths are at LO, how does this relate to NLO that is used? Or is there no difference?}. In \tab{tab:TTx}  the resulting NLO cross sections for the top-Z FCNC interactions are given.  
\begin{table}[htbp]
	\centering
	\caption{ Next to leading order top pair cross section for the top-Z FCNC interactions with with a full leptonic decay. }
	\begin{tabular}{ccll}
		\toprule
		Anomalous coupling & Process &   \multicolumn{2}{c}{Cross section (\pb)}  \\ 
		\midrule
\multirow{2}{*}{$\kappa_{\Ptop\PZ\Pup}/\Lambda$} & $\ttbar \rightarrow (\Pbottom \Pleptonplus\Pneutrino) (\APup \Pleptonplus \Pleptonminus)$ & 2.727008 $10^5$  & $\left( \kappa_{\Ptop\PZ\Pup}/\Lambda \right)^2$ \\
& $\ttbar \rightarrow (\APbottom \Pleptonminus\APneutrino) (\Pup \Pleptonplus \Pleptonminus)$ & 2.727008 $10^5$  & $\left( \kappa_{\Ptop\PZ\Pup}/\Lambda \right)^2$ \\
\multirow{2}{*}{$\kappa_{\Ptop\PZ\Pcharm}/\Lambda$} & $\ttbar \rightarrow (\Pbottom \Pleptonplus\Pneutrino) (\APcharm \Pleptonplus \Pleptonminus)$ &2.726257$10^5$  & $\left( \kappa_{\Ptop\PZ\Pcharm}/\Lambda \right)^2$ \\
 & $\ttbar \rightarrow (\APbottom \Pleptonminus\APneutrino) (\Pcharm \Pleptonplus \Pleptonminus)$ & 2.726257 $10^5$  & $\left( \kappa_{\Ptop\PZ\Pcharm}/\Lambda \right)^2$ \\
\multirow{2}{*}{$\zeta_{\Ptop\PZ\Pup}$} & $\ttbar \rightarrow (\Pbottom \Pleptonplus\Pneutrino) (\APup \Pleptonplus \Pleptonminus)$ & 2.827184   & $\left( \zeta_{\Ptop\PZ\Pup}\right)^2$ \\
 & $\ttbar \rightarrow (\APbottom \Pleptonminus\APneutrino) (\Pup \Pleptonplus \Pleptonminus)$ & 2.827184   & $\left( \zeta_{\Ptop\PZ\Pup}\right)^2$ \\
\multirow{2}{*}{$\zeta_{\Ptop\PZ\Pcharm}$} & $\ttbar \rightarrow (\Pbottom \Pleptonplus\Pneutrino) (\APcharm \Pleptonplus \Pleptonminus)$ & 2.806801  & $\left( \zeta_{\Ptop\PZ\Pcharm}\right)^2$ \\
& $\ttbar \rightarrow (\APbottom \Pleptonminus\APneutrino) (\Pcharm \Pleptonplus \Pleptonminus)$ & 2.806801  & $\left( \zeta_{\Ptop\PZ\Pcharm}\right)^2$ \\
		\bottomrule
	\end{tabular} 
	\label{tab:TTx}
\end{table}



\subsection{Generating \SM\  background events}
The SM \tZq events were generated using the \aMCMG\ generator, interfaced with \Pythia\ version 8.2~\cite{Sjostrand:2014zea}  for parton showering and hadronisation. The \WZ+jets, \ttZ, \tZq, and \ttW\ samples are produced using the \aMCMG (version 5.222)~\cite{Alwall:2014hca}, which includes up to one hadronic jet at next to leading order (NLO) QCD accuracy. Other minor background (e.g. \WW, \ZZ, \tWZ\ and \ttH) are simulated using different generators such as \MG~\cite{Alwall:2011uj},\MS~\cite{Artoisenet:2012st} and \JHU~\cite{Gritsan:2016hjl,Anderson:2013afp,Bolognesi:2012mm,Gao:2010qx}. All events are interfaced to \Pythia\ for parton shower and hadronisation. 

The complete list of \SM\ samples is given in Table \ref{tab:samples} \todocite, along with their cross sections. The cross sections without a reference are coming from the generator with which the sample has been made, for some of them the uncertainties are provided by the Generator Group. For each MC sample, the integrated luminosity that the sample represents is estimated as the number of simulated events divided by the cross section of the generated process. For processes generated with \aMCMG, the effective number of simulated events is used, taking into account positive and negative event weights. The correction factor for those events is defined as
\begin{equation}
\mathrm{C} = \frac{\textnormal{Nb. of pos. weights} + \textnormal{Nb. of neg. weights}}{\textnormal{Nb. of pos. weights} - \textnormal{Nb. of neg. weights}} \times \textnormal{mc baseweight}
\end{equation}

\begin{landscape}
	\begin{table}
		\centering
		\caption{SM MC samples used in this analysis with their corresponding cross section and \aMCMG\ correction C  when applicable. The generators used for each sample are indicated.  }
		\begin{tabular}{llll}
			\toprule
			Process & Generator & Cross section (\pb) & C \\ 
			\midrule
			$\WZ \rightarrow 3\Plepton\Pneutrino$ & \aMCMG +\Pythia & 5.26   & 1.61 \\ 
			
			\tZq\ with $\PZ\rightarrow \Pleptonplus \Pleptonminus$ & \aMCMG +\Pythia & 0.0758  & 3.77 \\ 
			
			\tqH\ with $\PHiggs \rightarrow \ZZ \rightarrow \Pleptonplus \Pleptonminus \Pleptonplus \Pleptonminus$& \JHU+\Pythia&8.80 10$^{-6}$ & - \\ 
			
			\ttW+jets with $\PW\rightarrow \Plepton\Pneutrino$ & \aMCMG +\MS+\Pythia & 0.2043 $\pm$ 0.0020  &1.94 \\ 
			
			
			%/TTWJetsToQQ\_TuneCUETP8M1\_13TeV-amcatnloFXFX-madspin-pythia8/ & 0.4062$\pm$ 0.0021 & -1 \\ 
			 
			$\ttZ\rightarrow 2\Plepton+2\Pneutrino+\mathrm{other}$, with $m_{\Plepton\Plepton}>10 \;\GeV$ & \aMCMG +\Pythia & 0.2529 $\pm$ 0.0004 & 2.15 \\ 
			
			\ttH,no \bbbar\ decays &\Powheg+\Pythia& 0.2151  & - \\ 
		
			\ttH, \bbbar\ decays& \Powheg+\Pythia & 0.2934  & - \\ 
			 
			$\WW\rightarrow 2\Plepton2\Pneutrino$& \Powheg +\Pythia & 12.178  & - \\
			
			$\ZZ\rightarrow 4\Plepton$ & \Powheg+\Pythia & 0.3366 & - \\ 
			 
			\WZZ & \aMCMG +\Pythia&0.05565  & 1.14 \\ 
		
			\ZZZ  & \aMCMG +\Pythia&0.01398  & 1.17 \\ 
		 
			\st\ \tWZ, with $\PZ_{\mu}\rightarrow \Pleptonplus\Pleptonminus$ & \MG +\Pythia&0.001123 & - \\ 
			
			%/ST\_s-channel\_4f\_leptonDecays\_13TeV-amcatnlo-pythia8\_TuneCUETP8M1 & 3 $\times$ 3.36 $^{+0.13}_{-0.12}$  & -1 \\ 
		
			\st\ t-channel \APtop  & \Powheg +\MS +\Pythia& 44.33 $^{+1.76}_{-1.49}$  & - \\ 
		
			\st\ t-channel \Ptop & \Powheg +\MS +\Pythia & 26.38 $^{+1.32}_{-1.18}$   & - \\ 
			
			\st\  $\bar{\mathrm{t}}\PW$ & \Powheg +\Pythia& 35.85 $\pm$ 0.90 (scale) $\pm$ 1.70 (PDF)   & - \\ 
		
			\st\ $\mathrm{t}\PW$ & \Powheg +\Pythia&35.85  $\pm$ 0.90 (scale) $\pm$ 1.70 (PDF) & - \\ 
			
			\ttbar &\Powheg +\Pythia & 831.76 $^{+19.77}_{-29.20}$$^{+35.06}_{-35.06}$   & - \\ 
			
			\DY, with $m_{\Plepton\Plepton}> \;50 \GeV$  & \aMCMG +\Pythia &3 $\times$( 1921.8 $\pm$  0.6 $\pm$ 33.2 ) & 1.49 \\ 
			
			\DY, with $10\; \GeV <m_{\Plepton\Plepton} < 50\; \GeV$ & \MG +\Pythia & 18610  & - \\ 
			\bottomrule 
		\end{tabular} 
		\label{tab:samples}
	\end{table}
\end{landscape}

%\subsection{Parton distribution functions and the hard interaction}
%\subsection{Parton showering}
%\subsection{Hadronisation and decay}
%explanation of jets https://profmattstrassler.com/articles-and-posts/particle-physics-basics/the-known-apparently-elementary-particles/jets-the-manifestation-of-quarks-and-gluons/
%\subsection{Underlying event}
\begin{comment}
%The draft document may be found at this URL: http://cds.cern.ch/record/2261310
%It is version no. 1 entitled:
%`Measurement of the underlying event using inclusive Z boson production in proton-proton collisions at sqrt(s) = 13 TeV`
% http://cms.cern.ch/iCMS/analysisadmin/cadi?ancode=FSQ-16-008
\end{comment}
%\subsection{Event reconstruction and identification}
% ICHEP https://cds.cern.ch/record/2005743
%\section{Event reconstruction}
\section{Multivariate analysis techniques: Boosted Decision Trees}
The need of processing large quantities of data and discriminating between events with largely similar experimental signatures makes multivariate statistical analysis (MVA) a largely used method in the physics community. Multivariate classification methods based on machine learning techniques are a fundamental ingredient to most analyses. The advantage of using a MVA classifier is that it can achieve a better discrimination power with respect to a simple cut and count analysis with a poorly discriminating variables. These variables are referred to as weak variables and have similar distributions for signal and background samples. 
A risk of using MVA classifiers is overtraining.  This happens when there are too many model parameters of an algorithm adjusted to too few data points. This leads to an increase in the classification performance over the objectively achievable one.

There are many software tools that exist for MVA. In this thesis the \texttt{Tool for Multivariate Analysis} (TMVA) \cite{2007physics3039H} is used. This software is an open source project included into \texttt{ROOT}~\cite{Brun:1997pa}. 
%http://idefix.mi.infn.it/~palombo/didattica/AnalisiStatistica/mvaLectures.pdf
All multivariate techniques in TMVA belong to supervised learning algorithms. By training on events for which the outcome is known, a mapping function is determined that describes a classification or an approximation of the underlying behaviour defining the target value (regression). 


In this thesis boosted decision trees (BDT) are employed for the classification of events as implemented in the \texttt{TMVA} framework~\cite{2007physics3039H}. This multivariate techniques is based on a set of decision trees where each yields a binary output depending on the fact that an event is signal- or background-like. The advantage of such a multivariate technique is that several discriminating variables can be combined into a powerful one-dimensional discriminant D. 

In \fig{fig:BDTexample} a schematic view of de decision tree is shown. The starting point is the root node. Then a consecutive set of a total of $i$ questions (nodes) regarding discriminating variables $x_\mathrm{i}$ are asked with only two possible answers per question (binary splits). The decision tree is constructed by training on a dataset for which the outcome is already provided, such as simulation dataset with signal and background processes (supervised learning). For each node a criterion $x_{\mathrm{i}}>C_{\mathrm{i}}$ is found by maximizing the separation gain between nodes 
\begin{equation}
\mathrm{separation}\:\mathrm{gain} \approx \mathrm{gain(parent)} - \mathrm{gain (daughter,Signal))} - \mathrm{gain (daughter,Background))},
\end{equation}
with the gain computed using the Gini index
\begin{equation}
 \mathrm{gain(cell)} \approx p (1-p), 
\end{equation}
where $p$ denotes the purity of a selection $x>C$. This is repeated until the maximum of nodes is reached and at the end of the sequence, the leaf nodes are labelled either signal S or background B, depending on the majority of events that end up on those nodes. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\linewidth]{3_Analysis_techniques/Figures/BDT}
	\caption{Schematic view of a decision tree. Figure taken from \cite{2007physics3039H}.}
	\label{fig:BDTexample}
\end{figure}

 Different trees can be combined into a forest where the final output is determined by the majority vote of all trees, forming the sum of so-called weak learners into one strong learner.   From one training collection, trees are derived by reweighting events, and combined into a single classifier as the  weighted average of each individual decision tree. A method for  making such forests is  boosting a tree. In this method, misclassified events are weighted higher so that future learner concentrate on these events. This has as advantage that the response of the decision trees are stabilised against fluctuations in the training sample which enhances the performance. Additionally, the trees can be kept very shallow, in this thesis i = 3, which improves the robustness against overtraining. Examples of such boosting algorithms are Adaptive Boosting (AdaBoost) and Gradient Boosting~\cite{2014arXiv1403.1452M}. In AdaBoost, each weight of the misclassified events are enhanced while reducing the weight of correctly classified events after each training such that  future events learn those better
\begin{equation}
 \alpha_{\mathrm{n+1}} = \left(\frac{1-\epsilon_{\mathrm{n}}}{\epsilon_{\mathrm{n}}}\right)^{\beta}, 
\end{equation}
where $\epsilon_{\mathrm{n}}$ denotes the misclassification error of the current tree n and $\beta$ is a learning rate. The weight $w_{\mathrm{i}}$ at node i is then equal to $w_{\mathrm{i}} = \mathrm{ln}\:\alpha_{\mathrm{i}}$. The final weight is the sum of all classifiers weighted by their errors. The learning rate is typically chosen to be $\beta\leqslant 0.5$ to allow more boosting steps. Gradient boosting has a similar approach and combines a gradient descent with boosting. Instead of fitting the base-learner to the reweighted data as in AdaBoost, it is fitted to the negative gradient vector of the loss function evaluated at the previous node. Misclassified events will result in a majority vote with large gradients of the loss function. Also for the Gradient boost, the learning rate is typically slow, this also known as shrinkage. In this thesis Gradient boost is used with a shrinkage of 0.2-0.3.
%http://www.ccs.neu.edu/home/vip/teach/MLcourse/4_boosting/slides/gradient_boosting.pdf
%https://indico.scc.kit.edu/indico/event/48/session/4/contribution/35/material/slides/0.pdf
%https://arxiv.org/pdf/1403.1452.pdf
%https://www.quora.com/What-is-the-difference-between-gradient-boosting-and-adaboost
% https://people.phys.ethz.ch/~pheno/Lectures2012_StatisticalTools/slides/Chanon2.pdf

In this thesis, the Gradient boost is used in combination with bagging, so-called stochastic gradient boosting. Bagging is a resampling technique draws a subset of events is  from the training data where the same event is allowed to be randomly picked several times from the parent sample. The tree is then trained on this subset and this is repeated many times. It is based on the assumption that sampling from a dataset that follows a distribution is the same as sampling from the distribution itself~\cite{Behnke:2013:DAH:2564838}. If one draws an event out of the parent sample, it is more likely to draw an event out of the phase space that has a high probability density, as the original dataset will have more events in the regions. Since the selected event is kept in the original sample, the parent sample stays unchanged so that randomly extracted samples have the same parent distribution, albeit statistically fluctuated.  Bagging smears over the statistical fluctuations in the training data, making it suitable for stabilising the response of the classifier and increasing the performance by eliminating overtraining.  In stochastic gradient boosting the bagging resampling procedure uses random sub-samples of the training events for growing the trees. 


The discriminating power of a BDT is assessed by analysing the receiver operating statistics (ROC) curve. This curves show the background rejection over the signal efficiency of the remaining sample. By looking at the area under the curve with respect to random guessing (AUC), the best classifier can be identified. This follows the Neyman-Pearson lemma that the best ROC curve is given by the likelihood ratio \like(x|Signal)/\like(x|Background)~\cite{Behnke:2013:DAH:2564838}. No discrimination power will result in an AUC of 0\%, while 50\%  means fully separated event classes. In \fig{fig:ROC} an example of ROC curve is shown. 
\begin{figure}[htbp]
	\centering
	\includegraphics[width=0.5\linewidth]{3_Analysis_techniques/Figures/ROC}
	\caption{Example of ROC curves. In this example, the green method is better than the red one, which is better than the blue one. The dashed line represents a case where there is no separation. Figure taken from \cite{ROC}.}
	\label{fig:roc}
\end{figure}




\section{Template-based fitting}
%\section{Statistics for a high energy particle physicist}
%\label{sec:Stat}

%\subsection{Boosted decision trees}
%\subsection{Confidence levels }

%https://indico.cern.ch/event/614672/timetable/#20170907
%\subsection{Combine limit setting tool}
%\section{Collision event generation}
